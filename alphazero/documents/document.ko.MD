# I. Minimax-Based Implementation (Brief Mention)

## 1.0 Project Goal

내가 지금 다니고 있는 학교 42에는 `Gomoku`라는 프로젝트 과제가 있다. 이 학교는 잘 알려져 있듯이, 학생이 스스로 자료를 수집하고 코드를 작성한 뒤, 결과를 보면서 프로젝트가 제대로 돌아갈 때까지 계속 수정해 가는 방식으로 진행된다.

이 과제를 처음 본 것은 약 4년 전, 입학 직후였다. 이미 AlphaGo라는 인공지능이 한바탕 시끄러웠던 시기가 지나간 뒤였고, 과제의 내용을 정확하게 이해하지는 못했지만 “AI를 만드는 과제”라고 인식했다. 그래서 학교를 마무리하기 전에 꼭 해보고 싶은 프로젝트로 마음속에 남아 있었다.

시간이 어느 정도 흐른 후 AI 쪽으로 커리어를 쌓기 위해 학교 내·외부에서 기반 지식을 쌓고 여러 과제들을 수행해 오면서, 결국 이 Gomoku 과제를 직접 맞닥뜨리게 되었다. 실제 과제의 내용은 내가 막연히 상상하던 것처럼 AlphaGo/AlphaZero 전체 모델을 직접 만들어 테스트하는 수준은 아니었지만, 졸업 요건을 위해 반드시 수행해야 하는 프로젝트였다.

또한 과제 보너스 항목(추가 점수)으로, 문서에서 제시된 알고리즘 대신 다른 알고리즘으로 평가를 받는 것도 가능했다. 이 선택이, 그 당시에는 전혀 예상하지 못했던, 중간에 여러 번 쉬어 가는 시간을 포함해 거의 1년에 가까운 긴 여정의 시작이었다.

---

## 1.1 Python Implementation

### 1.1.1 Basic Game & Project Requirements – 파이썬으로 시작하기

바둑(go)와는 다른 게임이지만, 오목(gomoku)는 바둑이 상대적으로 대중적인 동아시아 3국(한국, 일본, 중국)에서 쉽게 접할 수 있는 게임이다. 서양에서 tic-tac-toe나 othello를 하는 것처럼, 학생들이 쉬는 시간에 간단한 내기를 하면서 두기 좋은 게임이다.

하지만 과제를 위해 자료를 찾아보니 내가 알고 있던 “3-3 금지” 정도의 단순한 오목이 전부가 아니었다. 렌주룰, 4-3 금지 등 내가 전혀 모르던 규칙들이 많았고, 처음에는 이 세계가 꽤 복잡하고 부담스럽게 느껴졌다.

과제 PDF를 직접 공유할 수는 없지만, 핵심 요구 조건은 대략 다음과 같았다.

- 실행 파일 이름은 반드시 `Gomoku`일 것.
- 플레이어가 AI를 상대로 **진지하게 이기려고 해도** 결국 AI가 이기도록 게임을 설계할 것.
- 같은 컴퓨터에서 두 사람이 번갈아 두는 **hotseat 모드**를 제공하고, 이 모드에서도 한쪽 플레이어에게 **수 추천 기능**을 제공할 것.
- AI는 가능한 수들로 **해결 트리(possible-solution tree)**를 만들고, 이 트리를 기반으로 최선의 수를 고르는 구조여야 한다.
  - 핵심 탐색 알고리즘은 반드시 **Min-Max**를 사용할 것.
  - 트리 말단 노드의 가치를 평가하는 **휴리스틱 함수**를 직접 설계하고, 충분히 정확하면서도 빠르도록 실험과 개선을 반복해야 한다. (문서에서도 이 휴리스틱을 이 과제의 가장 어려운 부분이라고 강조한다.)
- 실제로 플레이할 수 있도록, 최소한 **사용 가능한 수준의 그래픽/텍스트 인터페이스**를 제공할 것.
- 필수는 아니지만, AI가 어떻게 생각하는지 중간 과정을 볼 수 있는 **디버깅용 표시나 모드**를 구현하는 것이 권장된다.
- 인터페이스 어딘가에, **AI가 다음 수를 찾는 데 걸린 시간**을 보여주는 타이머를 표시해야 한다.
  - 공식 문서에는 *평균 0.5초를 넘기면 프로젝트를 통과할 수 없다*는 내용이 있고, 나 역시 나중에 학교 Slack을 뒤지면서 이 기준을 다시 확인했다.
- 게임 규칙 측면에서, 과제는 기본 오목 규칙 외에 다음 두 가지 커스텀 룰 구현을 요구한다.
  - 상대 돌 두 개를 양쪽에서 끊어내는 **capture 규칙**.
  - 하나의 착수로 두 개의 free-three를 만드는 수를 금지하는 **double three(3-3) 금지 규칙**.

한창 Python으로 개발을 많이 하던 때라, 이 과제도 Python으로 수행하기로 결정했다. 우선은 보드 상태를 표현하는 자료구조와, 여기에 착수할 수 있는지 여부를 검사하는 기본 뼈대를 설계하는 것부터 시작했다.

---

### 1.1.2 Capture & Double-Three – 커스텀 룰 구현

과제에서 요구하는 커스텀 룰을 제대로 반영하려면, 단순히 “돌을 놓는다” 수준으로는 충분하지 않았다. 마지막 착점을 기준으로 여러 방향의 패턴을 검사해서:

- 두 개의 돌이 끊기는 상황을 감지해 **capture를 처리**하고,
- 해당 수가 **double three 금수**에 해당하는지 판정하는

별도의 로직이 필요했다.

[그림 삽입하기 - 캡처에 대한 설명]

capture 쪽은 비교적 직관적이었다. 돌을 하나 둔 뒤에, 가로·세로·대각선 방향으로 일정 패턴을 검사해 “내 돌 – 상대 돌 – 상대 돌 – 내 돌” 형태가 만들어지는 경우를 찾아내고, 그 사이에 끼인 두 개의 상대 돌을 보드에서 제거해 주면 된다. 이 과정을 네 방향에 대해 반복하면서, 한 수에 여러 capture가 동시에 발생하는 경우도 처리할 수 있게 했다.


[그림 삽입하기 - doublethree에 대한]
반면 double three 금지 판정은 훨씬 더 까다로웠다. 단순히 “열린 삼이 두 개 생기면 금수”라고 말로는 설명할 수 있지만, 실제 코드에서는:

- 현재 수를 둔 좌표를 기준으로
- 여러 방향에서 연속된 돌 패턴을 스캔하고
- 이 중에서 어느 것이 열린 세 수(three)인지 구분한 다음
- 그런 패턴이 **동시에 두 개 이상 생겼는지**를 계산해야 했다.

처음 구현할 때는 이해하기 쉬운 쪽을 선택해서, 조건을 하나씩 `if`문으로 풀어 쓰고, 각 방향을 전부 돌면서 검사하는 방식을 택했다. 규칙 자체를 정확하게 구현하는 게 우선이었기 때문이다.

하지만 이렇게 작성한 로직은 착수마다 검사해야 하는 경우의 수가 상당히 많아졌고, 특히 double three 판정은 생각보다 시간이 많이 걸렸다. 이 부분이 나중에 Minimax 탐색을 최적화할 때 **성능 병목 지점**으로 드러나면서, 별도로 튜닝을 해 줘야 하는 대상이 된다. 이 시점에서는 “룰을 제대로 구현했다”는 안도감이 더 컸지만, 동시에 이 로직이 이후 성능 이슈로 다시 돌아올 거라는 사실은 아직 체감하지 못하고 있었다.

---

### 1.1.3 Minimax – 순수 Minimax 알고리즘 적용

capture 기능과 double three 금지까지 포함한 보드를 구현한 뒤, 본격적으로 Minimax라는 알고리즘을 공부하기 시작했다.

간단히 이야기하면, 1대1 게임에서 Minimax는 현재 보드 상태를 루트 노드로 두고 시작한다. 한 플레이어가 둘 수 있는 모든 수를 한 번씩 다 둬 보고, 그다음에는 상대 플레이어가 둘 수 있는 모든 응수를 다시 전부 시뮬레이션한다. 또 그다음 턴에서도 가능한 모든 수를 계속 펼쳐 나가면서, 이 과정을 미리 정한 깊이 `n`까지 반복한다.

깊이 `n`에 도달하면 트리의 말단 노드들이 생기는데, 여기서부터 점수들을 계산해 부모 노드 방향으로 “타고 올라오게” 만든다. 이때 **내 턴인 노드에서는 자식들 중에서 최대값을 선택하고, 상대 턴인 노드에서는 자식들 중에서 최소값을 선택**한다. 이렇게 최대화 노드(MAX)와 최소화 노드(MIN)가 번갈아 가며 값을 선택해 루트까지 올라오면, 최종적으로 루트에서 선택되는 child 노드가 Minimax가 고른 최종 best move가 된다.

이 트리 구조에는 상대방도 항상 “가장 센 수를 둘 것”이라는 가정이 들어가 있으며, 그 전제를 기반으로 점수를 계산하는 방식이다.

[그림1- 루트노드와 자식노드 n1]
[그림2 - 자식노드들 n1의 자식노드들 n2]
[그림3 - 자식노드들 n2의 자식노드들 n3]
[그림4 - 자식노드들 n2의 자식노드들 n3]
[그림5 - 자식노드들 n3에서 스코어링]
[그림6 - 자식노드들 n2에서 스코어링]
[그림7 - 자식노드들 n1에서 스코어링]
[그림8 - 최선의 노드 선택]

현재 내가 만들고 있는 게임은 바둑판, 즉 19x19 사이의 돌 사이즈중 아무거나 둘 수 있지만, 선공일때는 19x19, 후공일 때는  19x19 - 1의 경우의 수의 점수를 모두 파악하기는 어렵다. 당연한 이야기 이지만 연산량이 늘어날 수록 검색을 해야 하는 양은 매우 많아지고, 또한 모든 경우의 수를 다 파악 할 필요는 없기 때문에 당연히 착수를 한 주변의 수, 선공일 때는 오목을 완성 하기 위해서는 중앙의 수가 유리, 엄밀히 말하자면 5개를 연속으로 둘 수 있는 공간이 확보 되어야 함 이 보장되어 있기 때문에 이정도만 생각하고 본격적인 minimax를 구현 해나가기 시작했다.

---

### 1.1.4 Python의 한계 – 너무 느린 첫 번째 구현

이렇게 Python으로 기본 로직을 마무리한 뒤, 현재 바둑판을 파싱하고 커스텀 룰과 Minimax를 적용한 아주 단순한 AI를 처음으로 시험해 보았다. 하지만 결과는 초기에 목표로 잡았던 **평균 500ms**와는 상당히 거리가 있었다. 깊이를 많이 주지도 않았는데, 한 수를 찾는 데 걸리는 시간이 체감상 “생각보다 심각하게 느린” 수준으로 나왔다.

간단한 코드 최적화—중복 계산을 줄이고, 불필요한 함수 호출을 없애고, 몇몇 자료구조를 바꾸는 정도—를 적용해 보았지만, 여전히 Minimax를 실용적인 깊이까지 돌리기에는 턱없이 부족한 속도였다. 멀티프로세싱이나 멀티스레딩 같은 방법도 잠깐 검토해 보았지만, 학교에서 제공하는 컴퓨터 스펙을 전제로 병렬화를 믿고 가기에는 리스크가 컸고, 무엇보다 **단일 프로세스 기준의 순수 연산 성능 자체가 너무 느리다**는 느낌이 강했다.

여기에 더해, Python이라는 언어가 구조적으로 이 문제에 불리한 점도 있었다. 간단한 정수 연산·배열 접근이 반복되는 Minimax 특성상, 다음과 같은 이유들 때문에 Python은 C++에 비해 느릴 수밖에 없다.

- **인터프리터 언어 특성**
  - Python 코드는 미리 기계어로 컴파일되어 실행되는 것이 아니라, **바이트코드 단위로 인터프리터가 한 줄 한 줄 해석하며 실행**된다.
  - Minimax처럼 자잘한 연산을 수없이 반복하는 코드에서는, 이 “해석 오버헤드”가 곧바로 실행 시간 증가로 이어진다.

- **동적 타이핑과 객체 오버헤드**
  - Python의 정수, 리스트, 딕셔너리 등은 모두 **힙에 할당된 객체**이고, 값 하나를 다루더라도 포인터 간접 참조, 참조 카운트 관리 같은 부가 비용이 따라온다.
  - 반면 C++에서는 `int`, `std::array`처럼 **스택/연속 메모리 상의 값 타입**을 쓸 수 있어, 같은 연산을 훨씬 적은 메모리 접근으로 처리할 수 있다.

- **함수 호출과 재귀 호출 비용**
  - Python 함수 호출은 상대적으로 무겁고, Minimax 구현은 보통 **재귀 호출이 깊게 중첩**된다.
  - 각 노드마다 작은 연산을 하고 재귀를 타는 구조에서는, 연산 자체보다 **함수 호출 오버헤드**가 더 커지는 구간도 생긴다.

- **메모리 지역성(cache locality) 부족**
  - Python 객체들은 메모리 여기저기에 흩어져 있고, 포인터를 따라가며 접근해야 한다.
  - C++에서는 보드를 2차원 배열이나 비트보드처럼 **연속된 메모리 블록**에 담을 수 있어서, CPU 캐시 히트율이 훨씬 좋아지고 순차 접근이 빠르다.

- **멀티스레딩 제약(GIL)**
  - 이 과제에서는 주로 단일 프로세스 기준 성능이 문제였지만, 어쨌든 Python은 **GIL(Global Interpreter Lock)** 때문에 스레드를 여러 개 만들어도 한 번에 하나의 스레드만 Python 바이트코드를 실행할 수 있다.
  - 즉, 스레드를 쓴다 해도 “코어 개수만큼 깔끔하게 속도가 늘어나는 그림”을 기대하기 어렵다.

이런 이유들 때문에, 단순히 알고리즘이나 구현을 조금 손보는 수준으로는 해결이 되지 않을 것 같다고 판단했다. 그래서 언어 차원의 오버헤드를 피하기 위해, 결국 핵심 로직을 C++로 이주하는 선택을 하게 된다.

---

## 1.2 Migration to C++

### 1.2.1 Basic implementation in C++ – Python 구현 이식

Python에서 C++로의 이주를 결정한 뒤, 기존 Python 코드를 참고하면서 C++ 버전을 다시 작성하기 시작했다. Python 버전에서도 기본적인 클래스 설계와 전체 구조는 어느 정도 잡혀 있었기 때문에, 로직 자체를 옮기는 작업은 크게 어렵지 않았다.

다만 이 단계에서는 **기능 구현**보다는 **실행 시간 단축**에 더 큰 비중을 두었다. 같은 Minimax 로직이라도, 언어와 자료구조 선택만 바꿔도 어느 정도 성능을 확보할 수 있을 것이라는 기대가 있었고, 실제로 C++로 옮기면서 이 부분을 적극적으로 활용하고자 했다.

이를 위해, C++ 구현에서는 단순한 2차원 배열이나 일반 컨테이너에 보드를 저장하는 대신, 핵심 연산 경로에는 **비트마스크(bitmask)**를 도입했다. 보드 상태를 비트 단위로 압축해 표현하면:

- 더 적은 메모리로 더 많은 칸 정보를 담을 수 있고,
- 비트 연산(`&`, `|`, `^`, `~`)을 이용해 여러 칸을 한 번에 검사할 수 있어서,
- Minimax 탐색 과정에서 자잘한 조건 검사들을 더 빠르게 처리할 수 있다.

즉, “한 칸당 정수 하나”로 관리하던 정보를 **비트보드(bitboard)** 형태로 압축해서, 연산 횟수와 메모리 접근을 동시에 줄이는 방향으로 구조를 재설계했다.

간단히 예시만 들면, 다음과 같이 하나의 정수에 여러 칸의 상태를 담고, 비트 연산으로 돌 유무를 확인하는 식이다(여기서는 설명을 위해 작은 보드를 가정했다).

```cpp
// C++98 기준 예시 (작은 보드를 가정한 개념용 코드)
typedef unsigned int Bitboard;

inline bool has_stone(Bitboard b, int idx) {
    return (b & (1u << idx)) != 0;
}

inline void place_stone(Bitboard &b, int idx) {
    b |= (1u << idx);
}
```
실제 19×19 보드 전체는 단일 unsigned int 하나로 표현하기에는 부족하지만, 이런 식의 비트마스킹 아이디어를 여러 개의 비트보드에 나누어 적용해, 패턴 검사와 라인 평가를 최대한 빠르게 만들고자 했다.


1.2.2 Performance Improvement – 체감 가능한 속도 향상

C++로의 이주와 비트마스킹 도입 이후, 같은 깊이의 Minimax 탐색을 수행했을 때의 실행 시간은 Python 대비 극적으로 개선되었다. 내 로컬 환경에서 간단히 측정해 본 결과:

- **Python 구현**: 깊이 3만 두고도 한 수를 찾는 데 **수 분 이상**을 기다려야 했다.
- **C++ 구현**: 같은 깊이에서 대체로 **2~3초 이내**에 수를 찾을 수 있었다.

정확한 수치는 머신 사양과 빌드 옵션에 따라 달라질 수 있지만, 체감상으로는 “실험용 프로토타입” 수준에 머물던 Python 버전이, C++로 옮긴 뒤에는 실제 게임에 투입할 수 있을 정도의 응답 시간을 확보했다고 느꼈다.

물론 이 시점의 구현은 여전히 과제의 목표인 **평균 0.5초(= 500ms)** 조건에는 못 미쳤다. 하지만 최소한 “언어 선택 때문에 막혀 있다”는 느낌은 사라졌고, **C++을 기반으로 더 공격적으로 최적화를 해 볼 만하다**는 확신을 가진 채 개발을 이어 나갈 수 있었다.

이 차이는 단순히 언어만 바꾼 결과가 아니라, 여러 요인이 겹친 결과였다.

- 인터프리터 기반인 Python에서 벗어나, **기계어로 컴파일된 코드**를 실행하게 된 점
- 보드 표현을 **비트보드(bitboard)** 형태로 바꾸어, 메모리 접근과 패턴 검사를 줄인 점
- 재귀 호출과 루프 내부에서 **불필요한 오버헤드**를 줄이도록 구현을 정리한 점

이 요소들이 합쳐지면서, Minimax의 논리 자체는 그대로 유지하면서도 실제 체감 속도는 전혀 다른 수준으로 올라갔다.

---------------------------- 정리 덜 된것들

0.
after expanding the code with applying couple of updates

dirichlet, temeprature, arena mode and etc

tested with 5x5 it went up to 1780 in 5x5, so went up to 19x19

-> ray 적용 / gpu 최적화 / gcp 설정 등등

그리고 나서 19x19 로 몇번 돌려 봤는데 성능이 제대로 안나왔다

코드를 살펴 보니 버그도 보였고, 근본적으로게임 룰에 맞게 이게 제대로 구현이 됬나 싶은 의문감이 들어서 리팩토링을 진행함

1. gomoku.py 리팩토링

- pybind11 적용 해서 doublethree의 병목을 줄이려고 노력했다

- pytest의 도입으로 코드의 정확도 상승

- plane의 개수 늘리기 (기존 6개에서) history + color + forbidden 을 추가해봄


2. model: 그대로 가면됨

3. pvmcts

- sequential: 그냥 mcts logic 그대로 구현함

- vectorize (나중에 수식할때 matrix 연산으로 이 과정이 왜 sequential 이 빠른지에 대해 수식으로 풀어 적기)
  - CPU-only + PyTorch 모델은 CPU에 올려서 사용. infer_batch 없으면 infer로 자동 폴백(duck typing).
  - Dirichlet 노이즈는 “초기 start node 확장”에만 적용, 이후 확장은 순수 softmax.
  - 액티브 세트 관리: visit_count >= num_searches나 터미널이면 즉시 스킵, 배치에 포함하지 않음.
  - 터미널 단축: 승리/무승부 상태는 추가 추론 없이 바로 백업(visit=1), 자식 확장 없음.
  - 재방문 리프: visit_count>0이어도 리프면 다시 추론·확장한다(0.0 백업 금지).
  - 배치 매핑: 중복 상태가 있어도 인덱스 순서대로 값이 매핑됨; 하나의 infer_batch로 처리.
  - 제약/성능 가정: GPU 미사용, numpy 연산 최적화 위주. batch_infer_size, min_batch_size로 지연/배치 크기 조절.
  - 용도 정리: 병렬 탐색·CPU 클러스터/멀티게임 진행에 적합, 소수 게임/디버깅은 sequential이 단순.

- mp
  - mp_sequential.py: multiprocessing 감잡기용 교육용 샘플 (배치/성능 고려 없음)
  - mp.py: VectorizeEngine 기반으로 인퍼런스만 IPC로 분리(선택/백업은 메인 프로세스). 배치 단위로 CPU 텐서를 큐에 보내고 응답 길이가 다르면 RuntimeError로 방어. 프로세스별 시드 재설정, BrokenPipe/EOF 로깅 후 안전 종료. 생각보다 간단함. mp.Queue로 요청/응답만 넘기는 단순 구조.
